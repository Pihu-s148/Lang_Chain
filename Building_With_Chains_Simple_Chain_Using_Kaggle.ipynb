{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 1: Install Required Libraries\n",
        "\n",
        "In the first cell of your Colab notebook, install the necessary libraries. LangChain and OpenAI are the primary libraries needed."
      ],
      "metadata": {
        "id": "EcFUQyv47uWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community openai kagglehub"
      ],
      "metadata": {
        "id": "HsY8Ab3Q7ygr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9e55fa-64da-4c6d-9094-d12aaed74601"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Using cached langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain_community)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.8 (from langchain_community)\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain_community) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_community) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain_community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.9 langchain-core-0.3.21 langchain_community-0.3.8 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **LangChain**: A framework for building applications with language models.\n",
        "\n",
        "- **OpenAI**: The library to interact with OpenAI's language models."
      ],
      "metadata": {
        "id": "UyMOg-w97z_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 2: Import Libraries and Set Up OpenAI API Key\n",
        "\n",
        "In the next cell, import the necessary modules and set up your OpenAI API key. You need to replace `\"YOUR_API_KEY\"` with your actual OpenAI API key."
      ],
      "metadata": {
        "id": "wRPeaTkK73bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import langchain\n",
        "import kagglehub\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "MJG_pQJI77jT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **OpenAI API Key**: This key is required to authenticate your requests to OpenAI's API. You can obtain it from [OpenAI's website](https://auth.openai.com/authorize?issuer=auth0.openai.com&client_id=DRivsnm2Mu42T3KOpqdtwB3NYviHYzwD&audience=https%3A%2F%2Fapi.openai.com%2Fv1&redirect_uri=https%3A%2F%2Fplatform.openai.com%2Fauth%2Fcallback&device_id=70c25419-0a68-4868-aaa0-6ac95051c26a&screen_hint=signup&max_age=0&scope=openid+profile+email+offline_access&response_type=code&response_mode=query&state=WEtzQ3ZIcV9RUW5uNGZYTUc3OU9Lak00fmZHQ3dlMzh%2BNlBZbjh1fi5%2BMA%3D%3D&nonce=Q0Y2Y0hocmpKQXZUWTFNQnNIckpKMFdBSnBXZEM1akF5Y2VkeXE3MWpjOA%3D%3D&code_challenge=cMl19UnF6Bn7h2FKgCKo6Ax_7W8LDvAeIP6PTm_gOC8&code_challenge_method=S256&auth0Client=eyJuYW1lIjoiYXV0aDAtc3BhLWpzIiwidmVyc2lvbiI6IjEuMjEuMCJ9&flow=control)."
      ],
      "metadata": {
        "id": "biBcpAY18AvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 3: Set Up The Kaggle Dataset\n",
        "\n",
        "In the next cell, import the kaggle dataset."
      ],
      "metadata": {
        "id": "uCiFdTqHYFO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file=kagglehub.dataset_download(\"niraliivaghani/flipkart-product-customer-reviews-dataset\")\n",
        "print(\"Path to the file: \",file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo8kiRcYTxXt",
        "outputId": "384f4e44-0111-40cf-a45d-e2aae1bf8733"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/niraliivaghani/flipkart-product-customer-reviews-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.79M/3.79M [00:00<00:00, 153MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to the file:  /root/.cache/kagglehub/datasets/niraliivaghani/flipkart-product-customer-reviews-dataset/versions/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the correct CSV file in the directory\n",
        "dataset_directory = file # This is the directory returned by kagglehub\n",
        "csv_files = [f for f in os.listdir(dataset_directory) if f.endswith('.csv')]\n",
        "\n",
        "if len(csv_files) == 0:\n",
        "    raise FileNotFoundError(\"No CSV files found in the dataset directory.\")\n",
        "elif len(csv_files) > 1:\n",
        "    print(\"Multiple CSV files found. Using the first one:\", csv_files[0])\n",
        "\n",
        "# Construct the full path to the CSV file\n",
        "csv_path = os.path.join(dataset_directory, csv_files[0])\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Dataset loaded successfully.\")\n",
        "\n",
        "\n",
        "print(df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC8Daj2RUR21",
        "outputId": "9473791f-a2d7-46e2-fc18-7f4945142e84"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully.\n",
            "                                        product_name product_price Rate  \\\n",
            "0  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
            "1  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
            "2  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
            "3  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
            "4  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
            "5  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
            "6  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
            "7  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
            "8  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
            "9  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    4   \n",
            "\n",
            "               Review                                            Summary  \\\n",
            "0              super!  great cooler excellent air flow and for this p...   \n",
            "1             awesome              best budget 2 fit cooler nice cooling   \n",
            "2                fair  the quality is good but the power of air is de...   \n",
            "3     useless product                  very bad product its a only a fan   \n",
            "4                fair                                      ok ok product   \n",
            "5             awesome  the cooler is really fantastic and provides go...   \n",
            "6  highly recommended                                  very good product   \n",
            "7                nice                                          very nice   \n",
            "8      unsatisfactory                                    very bad cooler   \n",
            "9     worth the money                                          very good   \n",
            "\n",
            "  Sentiment  \n",
            "0  positive  \n",
            "1  positive  \n",
            "2  positive  \n",
            "3  negative  \n",
            "4   neutral  \n",
            "5  positive  \n",
            "6  positive  \n",
            "7  positive  \n",
            "8  negative  \n",
            "9  positive  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Step 4: Define and Run the Chain\n",
        "\n",
        "In the next cell, define a simple chain using LangChain and run it."
      ],
      "metadata": {
        "id": "3rgiODvU8L6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Chain\n",
        "prompt = PromptTemplate(\n",
        "    template=\"What was the review for the {product_name}?\",\n",
        ")\n",
        "chain = LLMChain(llm=OpenAI(), prompt=prompt)\n"
      ],
      "metadata": {
        "id": "5Z6oFl7p8BUb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain\n",
        "product_name = \"Candes 12 L Room/Personal Air Cooler\"\n",
        "chain.invoke(product_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvrMBwlbU0m9",
        "outputId": "fe949471-2597-4c76-afbf-6906fce3fe7d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'product_name': 'Candes 12 L Room/Personal Air Cooler',\n",
              " 'text': '\\n\\nThe review for the Candes 12 L Room/Personal Air Cooler was mostly positive. Users praised its compact and portable design, making it easy to move from room to room. They also appreciated its strong cooling performance, even in hot and humid weather. The air cooler was also noted for its low noise level and energy efficiency. However, some users mentioned that the water tank could have been larger and that the cooler was not very effective in larger rooms. Overall, the majority of reviewers were satisfied with their purchase and would recommend it to others.'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- **Prompt**: The input text that you provide to the language model. In this case, it's a request to generate a marketing email.\n",
        "\n",
        "- **LLMChain**: A LangChain object that manages the interaction with the language model. It takes a language model (`llm`) and a `prompt`.\n",
        "\n",
        "- **Run the Chain**: The `run` method executes the chain and returns the response from the language model."
      ],
      "metadata": {
        "id": "yIui3wBY8ROq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Additional Resources\n",
        "\n",
        "- **LangChain Documentation**: [LangChain Docs](https://langchain.readthedocs.io/en/latest/)\n",
        "\n",
        "- **OpenAI API Documentation**: [OpenAI API Docs](https://platform.openai.com/docs/api-reference/introduction)"
      ],
      "metadata": {
        "id": "kh8AN6BY8Wjb"
      }
    }
  ]
}